{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 딥러닝\n",
    "\n",
    "- 딥러닝의 특징과 과제, 그리고 가능성\n",
    "- 오늘날의 첨단 딥러닝\n",
    "\n",
    "에 대해 살펴본다. (본 책은 2016년 9월에 나왔음을 생각하자. 저자는 이 책을 약 1년 반 전부터 구상하고 집필하였다고 한다.) \n",
    "\n",
    "이번 챕터는 코드 실습이 없다. 설명도 자세하진 않다. 여러 가지가 있구나 알아가면 되겠다. \n",
    "\n",
    "## 8.1 더 깊게. \n",
    "\n",
    "### 8.1.1 더 깊은 신경망으로 \n",
    "\n",
    "다음과 같은 Deep한 MNIST 손글씨 인식 네트워크를 만들어보자. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-1.png\" width=500>\n",
    "\n",
    "- 3*3의 작은 필터를 사용한 합성곱 계층\n",
    "- 활성화 함수는 ReLU\n",
    "- 완전연결 계층 뒤에 드롭아웃 계층 사용\n",
    "- Adam을 사용해 최적화\n",
    "- 가중치 초깃값은 He 초깃값. \n",
    "\n",
    "3*3의 작은 필터를 사용했음에도 실습파일 deep_convnet.py의 신경망을 train_deepnet.py에서 학습시키면 거의 반나절이 걸린다고 한다. 이미 학습된 W를 읽으려면 deep_conv_net_params.pkl에서 읽으면 된다. \n",
    "\n",
    "딥러닝은 학습에 시간이 많이 걸린다. \n",
    "\n",
    "### 8.1.2 정확도를 더 높이려면? \n",
    "\n",
    "앙상블 학습, learning rate decay 등 많지만 그 중 데이터 확장(data augmentation)이 손쉬우면서 정확도 개선에 효과적이다. \n",
    "\n",
    "data augmentation은 알고리즘을 동원해 입력 이미지(훈련 이미지)를 인위적으로 확장한다. (회전, 세로로 이동 등 미세한 변화 줌.) \n",
    "\n",
    "이는 데이터가 몇 개 없을 때 특히 효과적인 수단이다. \n",
    "\n",
    "이미지의 일부를 crop하거나 좌우를 뒤집는 flip, 밝기 변화, 확대/축소 스케일 변화 등도 가능하다. \n",
    "\n",
    "### 8.1.3 깊게 하는 이유\n",
    "\n",
    "'층을 깊게 하는 것'이 왜 중요한가에 대한 이론적 근거는 아직 많이 부족한 것이 사실이다. 그럼에도 지금까지의 연구 결과에서 설명을 조금 얻을 수 있다. \n",
    "\n",
    "이점:\n",
    "\n",
    "1. 신경망의 매개변수 수가 줄어든다. \n",
    "    - 층이 깊으면 얕은 신경망보다 적은 매개변수로 같거나 그 이상의 표현력을 달성할 수 있다. \n",
    "\n",
    "이를 설명하기 위해 CNN의 예를 들어보자. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-5.png\" width=500>\n",
    "\n",
    "여기선 5*5 = 25개의 매개변수가 필요하다. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-6.png\" width=500>\n",
    "\n",
    "이는 3*3필터 *2번 = 18개의 매개변수로도 계산이 가능하다. \n",
    "\n",
    "이러한 매개변수 갯수의 차이는 층이 깊어지며 더 커진다. \n",
    "\n",
    "이렇게 작은 필터를 겹쳐 신경망을 깊게하면 매개변수 수가 줄기 때문에 넓은 수용 영역(receptive field, 뉴런에 변화를 일으키는 국소적인 공간 영역)을 소화할 수 있다. \n",
    "\n",
    "또한 층을 거듭하며 ReLU 등의 활성화 함수를 사이에 끼워 신경망의 표현력이 개선된다. \n",
    "\n",
    "이는 활성화 함수가 신경망에 '비선형' 힘을 가하고, 비선형 함수가 겹치면서 더 복잡한 것도 표현할 수 있게 되기 때문이다. \n",
    "\n",
    "2. 학습의 효율성이 높아진다. \n",
    "    - 층이 깊어지면 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있다. \n",
    "    - 이를 직관적으로 이해해보면, 개를 인식할 때 층이 얕으면 한 번에 모든 특징을 이해해야 하지만 층이 깊으면 더 단순한 문제로 분해해 blob/edge --> 더욱 추상화된 패턴 을 이해할 수 있기 때문이다. \n",
    "    - 이렇게 층을 깊게 하면 정보를 계층적으로 전달할 수 있어 다음 층이 이전 층의 low level 정보를 사용해 더욱 고도의 패턴을 효과적으로 학습할 것이라 기대가 가능하다. \n",
    "    \n",
    "## 8.2 딥러닝의 초기 역사\n",
    "\n",
    "ILSVRC(ImageNet Large Scale Visual Recognition Challenge) 2012 대회에서 딥러닝이 압도적인 성적을 거두며 대세가 되었다. \n",
    "\n",
    "### 8.2.1 이미지넷\n",
    "\n",
    "ImageNet의 classification competition에서 2012년 이후 딥러닝이 계속 1등을 했다. 2015년의 ResNet은 오류율을 3.5%까지 낮추며 인간의 인식 능력을 넘어섰다. \n",
    "\n",
    "특히 유명한 VGG, GoogLeNet, ResNet에 대해 알아보자. \n",
    "    \n",
    "### 8.2.2 VGG\n",
    "\n",
    "합성곱 계층과 풀링 계층으로 구성되는 기본적은 CNN. \n",
    "\n",
    "하지만 합성곱 계층과 완전연결 계층을 16 또는 19 층으로 심화한 것이 특징. \n",
    "\n",
    "주목할 점은 3*3의 작은 필터를 사용한 합성곱 계층을 연속으로 거친다는 점. 2~4회 연속으로 pooling 계층을 두어 크기를 절반으로 줄이는 처리를 반복한다. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-9.png\" width=500>\n",
    "\n",
    "### 8.2.3 GoogLeNet \n",
    "\n",
    "그림의 사각형이 계층을 나타낸다. \n",
    "\n",
    "GoogLeNet은 세로뿐만 아니라 가로로도 깊다는 것이 특징. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-10.png\" width=500>\n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-11.png\" width=500>\n",
    "\n",
    "인셉션 구조는 크기가 다른 필터와 풀링을 여러 개 적용해 그 결과를 결합한다. 이를 building block(구성 요소)로 사용하는 것이 특징. \n",
    "\n",
    "또한 1*1 크기의 필터를 사용한 합성곱 계층을 많은 곳에서 사용해 채널 크기를 줄여 매개변수 제거와 고속처리에 기여하는 것도 특징. \n",
    "\n",
    "### 8.2.4 ResNet\n",
    "\n",
    "Residual Network는 마이크로소프트에서 개발했다. \n",
    "\n",
    "특징은 지금까지보다 층을 더 깊게 할 수 있는 특별한 장치가 있다는 것이다. \n",
    "\n",
    "딥러닝은 너무 깊으면 학습이 오히려 잘 되지 않고 성능이 떨어지는 경우도 많은데, ResNet은 그 문제 해결을 위해 skip connection(스킵 연결)을 도입했다. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-12.png\" width=500>\n",
    "\n",
    "스킵 연결이란 위와 같이 입력 데이터를 합성곱 계층을 건더뛰어 출력에 빠로 더하는 구조이다. (weight layer가 합성곱 계층임.)\n",
    "\n",
    "두 합성곱 계층을 건너뛰고 출력에 바로 연결해 F(x) 대신 F(x) + x가 되는 것이 핵심이다. \n",
    "\n",
    "이렇게 하면 층이 깊어져도 backpropagation 시 신호 감쇠(vanishing gradient 같은 것)를 막아준다. 입력 데이터를 그대로 흘리므로 역전파 때도 상류의 기울기를 그대로 보내기 때문. \n",
    "\n",
    "이 구조가 층의 깊이에 비례해 성능을 향상시킬 수 있게 한 핵심이다. (물론 층을 계속 깊게 하는 것은 여전히 한계가 있음.)\n",
    "\n",
    "ResNet은 앞의 VGG를 기반으로 스킵연결을 도입해 층을 깊게 했다. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-13.png\" width=500>\n",
    "\n",
    "150층 이상으로 쌓아도 정확도가 오르는 모습을 확인할 수 있었다. \n",
    "\n",
    "<br>\n",
    "\n",
    "ImageNet에서 제공한 데이터로 학습한 가중치들은 실제로도 쓸 수 있고 많이들 그렇게 하고 있다. \n",
    "\n",
    "이를 전이 학습(Transfer Learning)이라 부른다. 학습된 가중치의 전부 또는 일부를 다른 신경망에 복사한 다음 그 상태로 재학습을 수행하는 것. \n",
    "\n",
    "VGG와 구성이 같은 신경망을 만들고 초기값으로 학습된 가중치를 넣고 새로운 데이터셋을 받아 재학습(fine tuning) 하는 것. \n",
    "\n",
    "보유한 data set이 적을 때 특히 유용한 방법이다. \n",
    "\n",
    "## 8.3 더 빠르게(딥러닝 고속화). \n",
    "\n",
    "딥러닝 프레임워크 대부분은 GPU를 활용해 대량의 연산을 처리한다. \n",
    "\n",
    "### 8.3.1 풀어야 할 숙제 \n",
    "\n",
    "딥러닝에서 어떤 처리에 시간이 많이 소요될까? \n",
    "\n",
    "AlexNet의 경우를 보자. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-14.png\" width=500>\n",
    "\n",
    "Convolutional layer에서 많은 시간을 소요한다. (GPU에선 95%, CPU에선 89%) \n",
    "\n",
    "이를 고속화하는 것이 과제이다. (convolution. 즉 단일 곱셈-누산을 어떻게 빠르게 계산할 것인가.) \n",
    "\n",
    "### 8.3.2 GPU를 활용한 고속화 \n",
    "\n",
    "GPU는 CPU와 반대로 대량 병렬 연산에 특화되어있다. \n",
    "\n",
    "CPU로 40일 걸릴 것이 6일 걸린다. \n",
    "\n",
    "cuDNN이라는 딥러닝 특화 최적화 라이브러리를 사용하면 더욱 빨라진다. \n",
    "\n",
    "AMD, NVIDIA 모두 GPU를 개발하지만 대부분의 딥러닝 프레임워크는 NVIDIA에서만 혜택을 받을 수 있다. \n",
    "\n",
    "NVIDIA의 GPU 컴퓨팅용 통합 개발 환경인 CUDA를 사용하기 때문이다. (cuDNN도 여기서 동작함.)\n",
    "\n",
    "앞에서 본 img2col 방식으로 대행렬을 만들어 계산할 때 특히 아주 GPU가 제격이다. \n",
    "\n",
    "### 8.3.3 분산 학습\n",
    "\n",
    "딥러닝엔 시행착오가 따르기에 긴 학습시간을 (며칠 또는 몇 주) 감당하기 힘들다. \n",
    "\n",
    "그래서 딥러닝 학습을 수평 확장(scale out == 분산학습) 하자는 아이디어가 중요해진다. \n",
    "\n",
    "즉, 다수의 GPU와 다수의 PC로 계산을 분산하는 것이다. \n",
    "\n",
    "Google의 Tensorflow와 Microsoft의 CNTK(Computational Network Toolkit)은 분산 학습에 역점을 두고 개발되고 있다. \n",
    "\n",
    "Tensorflow에서 1대를 쓸 때보다 100대를 쓰면 56배까지 빨라진다. (7일 작업 --> 3시간)\n",
    "\n",
    "low latency(저지연), high throughput(고처리) 등을 동반하는 어려운 문제이므로 이는 프레임워크에 맡기도록 하자. \n",
    "\n",
    "### 8.3.4 연산 정밀도와 비트 줄이기 \n",
    "\n",
    "메모리 용량(많은 매개변수와 중간 데이터를 올려야 함.)과 버스 대역폭(CPU/GPU 버스에 흐르는 데이터가 많이지니까.) 등에 의해 병목이 발생할 수 있다. \n",
    "\n",
    "따라서 데이터와 비트 수를 최소화하는 것이 중요하다.\n",
    "\n",
    "딥러닝은 높은 수치 정밀도를 요구하지 않는다는 특징이 있다. Robust하기 때문이다. 즉, 데이터를 약간 퇴화시켜도 출력에 주는 영향이 적다. \n",
    "\n",
    "지금까지의 실험을 통해 64비트 double-precision 또는 32비트 single-precision 대신 16비트 half-precision을 써도 문제가 없다고 알려져있다. \n",
    "\n",
    "NVIDIA Pascal에서 이 포멧을 지원하여 반정밀도 부동소수점이 표준으로 사용될 수 있을 것이다. (2016년 기준이라는 것을 생각하자.) \n",
    "\n",
    "이러한 비트 최소화 기술은 앞으로도 주시해야 할 기술이다. \n",
    "\n",
    "## 8.4 딥러닝의 활용\n",
    "\n",
    "딥러닝은 여러 분야에 사용될 수 있다. 여기선 Computer Vision 중심으로 살펴보겠다. \n",
    "\n",
    "### 8.4.1 사물 검출\n",
    "\n",
    "이미지 속에 담긴 사물의 위치와 종류(class)를 알아내는 것이다. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-17.png\" width=500>\n",
    "\n",
    "사물 인식은 이미지 전체를 대상으로 했는데 사물 검출은 이미지 일부에서 사물의 위치, 갯수까지 알아내야 하기에 더 어렵다. \n",
    "\n",
    "여러 방법 중 R-CNN(Regions with CNN)이 유명하다. R-CNN의 처리 흐름을 보면 아래와 같다. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-18.png\" width=500>\n",
    "\n",
    "여기서 특히 2. 와 3. 을 주목해보자. \n",
    "\n",
    "2 에선 SVM 등을 사용하는 등 원리가 복잡하지만 이미 computer vision 분야에 많은 다양한 기법을 사용해 영역을 추출하는 것이 가능하다. \n",
    "\n",
    "3 에선 CNN을 쓴다. \n",
    "\n",
    "최근엔 2. 마저도 CNN으로 처리하는 Faster R-CNN 기법도 등장했다. 이 기법은 모든 일을 하나의 CNN에서 처리하기 때문에 훨씬 빠르다. \n",
    "\n",
    "### 8.4.2 분할\n",
    "\n",
    "segmentation은 이미지를 픽셀 수준에서 분류하는 문제이다. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-19.png\" width=500>\n",
    "\n",
    "단순한 방법을 생각하면 모든 픽셀을 각각 추론하는 것이 되겠지만 픽셀 수만큼 forward 해야 하고 Conv layer에서 많은 부분을 쓸데없이 계산해야 해 느려진다. \n",
    "\n",
    "이 낭비를 줄이기 위해 FCN(Fully COnvolutional Network)가 고안되었다. 이는 한 번의 Forward 처리로 모든 픽셀의 클래스를 분류해주는 대단한 기법이다. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-20.png\" width=500>\n",
    "\n",
    "FCN에선 앞에서 중간 중간 넣었던 완전연결 계층을 쓰지 않고, 같은 기능을 하는 Conv layer로 대체한다. \n",
    "\n",
    "앞의 사물 인식에서 사용한 신경망의 완전 연결 계층에선 중간 데이터의 공간 볼륨을 1차원으로 변환해 한 줄로 늘어선 노드들이 처리했으나 FCN에선 공간 볼륨을 유지한 채 마지막 출력까지 처리 가능하다. \n",
    "\n",
    "또한 FCN은 마지막에 공간 크기를 확대하는 처리를 도입했다는 것도 특징이다. 이 마지막 확대는 이중 선형 보간(bilinear interpolation)에 의한 선형 확대이다. \n",
    "\n",
    "FCN에선 이 선형 확대를 역합성곱(deconvolution) 연산을 통해 구현한다. \n",
    "\n",
    "### 8.4.3 사진 캡션 생성\n",
    "\n",
    "컴퓨터 비전과 자연어 처리를 융합한 연구이다. 사진을 보고 사진을 설명하는 글을 자동으로 생성하는 것이다. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-21.png\" width=500>\n",
    "\n",
    "방법으론 NIC(Neural Image Caption) 모델이 대표적이다. \n",
    "\n",
    "NIC는 Deep CNN과 자연어를 다루는 RNN으로 구성된다. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-22.png\" width=500>\n",
    "\n",
    "CNN으로 사진에서 특징을 추출해 이걸 RNN에 넘겨 텍스트를 순환적으로 생성하는 것이다. \n",
    "\n",
    "이렇게 사진, 자연어 등 여러 종류의 정보를 조합하고 처리하는 것을 멀티모달 처리(multimodal processing)이라 하여 최근 주목받는 분야이다. \n",
    "\n",
    "## 8.5 딥러닝의 미래\n",
    "\n",
    "### 8.5.1 이미지 스타일(화풍) 변환\n",
    "\n",
    "콘텐츠 이미지 & 스타일 이미지 두 이미지를 입력받아 새로운 그림을 그린다. \n",
    "\n",
    "고흐 풍으로 그리는 유명한 모델이 이것이다. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-23.png\" width=500>\n",
    "\n",
    "대략적으로 설명하자면 이 기술은 네트워크의 중간 데이터가 콘텐츠 이미지의 중간 데이터와 비슷해지도록 학습한다. \n",
    "\n",
    "또한 스타일 이미지의 화풍을 흡수하기 위해 스타일 행렬이라는 개념을 도입하여 이 행렬의 오차를 줄이도록 학습하는 것이다. \n",
    "\n",
    "요즘은 앱도 많다. \n",
    "\n",
    "### 8.5.2 이미지 생성\n",
    "\n",
    "먼저 대량의 이미지로 학습시키면 학습 이후엔 아무 입력 이미지 없이도 이미지를 생성해낸다. \n",
    "\n",
    "DCGAN(Deep Convolutional Generative Adversarial Network)으로 새롭게 침실 이미지를 생성한다. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-24.png\" width=500>\n",
    "\n",
    "DCGAN의 핵심은 Generator 네트워크와 Discriminator 네트워크를 두 개 만들어 서로 겨루도록 학습해 가짜 이미지를 만들어낸다. \n",
    "\n",
    "단지 이미지만 여러 개 주어지면 학습하는 것이니 unsupervised learning에 해당한다. \n",
    "\n",
    "### 8.5.2 자율 주행\n",
    "\n",
    "자율주행은 주변을 정확히 인식하는 것이 중요하다. \n",
    "\n",
    "SegNet이라는 CNN 기반 신경망의 예를 보자. \n",
    "\n",
    "<img src=\"../deep_learning_images/fig_8-25.png\" width=500>\n",
    "\n",
    "### 8.5.4 Deep Q-Network(강화학습)\n",
    "\n",
    "Reinforcement Learning은 Agent가 Environment에 맞게 Action을 선택해 이에 의한 변화에 (예상)Reward를 받고 이에 기반해 최적화 해나간다. \n",
    "\n",
    "## 8.6 정리\n",
    "\n",
    "- 수많은 문제에서 신경망을 더 깊게 하여 성능을 개선할 수 있다. \n",
    "- 이미지 인식 기술 대회인 ILSVRC에서는 최근 딥러닝 기반 기법이 상위권을 독점하고 있으며, 그 깊이도 더 깊어지는 추세이다. \n",
    "- 유명한 신경망으로는 VGG, GoogLeNet, ResNet이 있다. \n",
    "- GPU와 분산 학습, 비트 정밀도 감소 등으로 딥러닝을 고속화 할 수 있다. \n",
    "- 딥러닝(신경망)은 사물 인식뿐 아니라 사물 검출과 분할에도 이용할 수 있다. \n",
    "- 딥러닝의 응용 분야로는 사진의 캡션 생성, 이미지 생성, 강화학습 등이 있다. 최근에는 자율 주행에도 딥러닝을 접목하고 있어 기대된다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
